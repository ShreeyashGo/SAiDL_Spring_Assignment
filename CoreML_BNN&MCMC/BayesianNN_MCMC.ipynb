{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreeyashGo/SAiDL_Spring_Assignment/blob/main/CoreML_BNN%26MCMC/BayesianNN_MCMC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2j4DM-DRIBL"
      },
      "source": [
        "<h3> Create the dataset and visualize the data\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTo-IGx9eXuG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#so lets create a dataset of 10k data points\n",
        "num = 10000\n",
        "\n",
        "np.random.seed(0)\n",
        "x1 = np.random.rand(num, 1)\n",
        "\n",
        "np.random.seed(1)\n",
        "x2 = np.random.rand(num, 1)\n",
        "\n",
        "#creating the dataset\n",
        "data = np.hstack((x1, x2))\n",
        "\n",
        "#we will now create the labels using 1:1 corresponding mapping\n",
        "labels = np.zeros_like(data[:, 0])\n",
        "temp = data.copy()\n",
        "temp[temp>=0.5] = 1\n",
        "temp[temp<0.5] = 0\n",
        "temp = temp.astype(np.int32)\n",
        "for i in range(num):\n",
        "    labels[i] = temp[i][0] ^ temp[i][1] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYpfQWVccDQ-"
      },
      "outputs": [],
      "source": [
        "#lets plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "col = np.where(labels[:500]==1,'orange', 'blue')\n",
        "plt.scatter(data[:500, 0], data[:500, 1], c= col)\n",
        "plt.fill_between([0, 0.5], 0, 0.5, color='tab:blue', alpha=0.2)\n",
        "plt.fill_between([0.5, 1], 0, 0.5, color='tab:orange', alpha=0.2)\n",
        "plt.fill_between([0, 0.5], 0.5, 1, color='tab:orange', alpha=0.2)\n",
        "plt.fill_between([0.5, 1], 0.5, 1, color='tab:blue', alpha=0.2)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLOAcbc1mkYn"
      },
      "outputs": [],
      "source": [
        "#just to free up some memory\n",
        "del col, temp, x1, x2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8P8uQ1JRIBp"
      },
      "source": [
        "<h3> Creating the algorithm</h3>\n",
        "<br>\n",
        "For an MLP to replicate XOR functionality, we need at least 1 hidden layer due to the non linearity!\n",
        "So I have created this architecture which has input layer + 2 layers(2 neurons and 1 neuron respectively)<br>\n",
        "XOR(x1,x2) = AND(OR(x1, x2), NAND(x1,x2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PARPmGvKvAe"
      },
      "outputs": [],
      "source": [
        "proposal_sig = 2\n",
        "\n",
        "class XOR_NN():\n",
        "    # the MLP class\n",
        "    def __init__(self, sed=None):\n",
        "        #get seed to check results with the same start point\n",
        "        np.random.seed(sed)\n",
        "        self.layer1 = np.array(np.random.randn(2,3)+[[5, 5, -4], [-3, -3, 4]], dtype = np.float64)   #warm starting\n",
        "        if sed != None: np.random.seed(sed+1)\n",
        "        self.layer2 = np.array(np.random.randn(1,3)+[3, 3, -4], dtype = np.float64)\n",
        "        self.weights = [0, 0]\n",
        "        self.weights[0] = self.layer1\n",
        "        self.weights[1] = self.layer2\n",
        "        self.weights = np.asarray(self.weights, dtype = object)\n",
        "\n",
        "    def sig(self, xS):\n",
        "        #sigmoid implementation\n",
        "        for i in range(len(xS)):\n",
        "            xS[i] = 1/(1+np.exp(-xS[i]))\n",
        "        return xS\n",
        "    \n",
        "    def forward(self, inp: np.array):\n",
        "        #a forward pass\n",
        "        self.inp = np.append(inp, 1).reshape(1,3)\n",
        "        self.hid_rep = np.matmul(self.inp, np.transpose(self.weights[0]))\n",
        "        self.hid_rep = self.sig(self.hid_rep)\n",
        "        self.hid_rep = np.append(self.hid_rep, 1)\n",
        "        self.op = np.matmul(self.hid_rep, np.transpose(self.weights[1]))\n",
        "        self.op = self.sig(self.op)\n",
        "        return self.op\n",
        "    \n",
        "\n",
        "def gen_temp(x):\n",
        "    #generate a proposal!\n",
        "    templayer1 = np.array(np.random.randn(2,3))*proposal_sig + x[0]\n",
        "    templayer2 = np.array(np.random.randn(1,3))*proposal_sig + x[1]\n",
        "    temp = [0, 0]\n",
        "    temp[0] = templayer1\n",
        "    temp[1]= templayer2\n",
        "    temp = np.asarray(temp, dtype = object)\n",
        "    temp_model = XOR_NN()\n",
        "    temp_model.weights = temp\n",
        "    return temp_model  #x as the mean and std of proposal distribution as proposal_sig uniform for all weights\n",
        "\n",
        "\n",
        "def prior(x: XOR_NN):\n",
        "    #designed prior to check conditions on the weights beinging in accordance to the OR/NAND/AND functions!\n",
        "    p=1\n",
        "    wt = x.weights\n",
        "    if(3*wt[0][0][0] < wt[0][0][2]):\n",
        "         p+=1\n",
        "    if(3* wt[0][0][1] < wt[0][0][2]):\n",
        "        p+=1\n",
        "    if(wt[0][1][0] > 3*wt[0][1][2]):\n",
        "        p+=1\n",
        "    if(wt[0][1][1] > 3*wt[0][1][2]):\n",
        "        p+=1\n",
        "    if(3*wt[1][0][0] < wt[1][0][2]):\n",
        "        p+=1\n",
        "    if(3*wt[1][0][1] < wt[1][0][2]):\n",
        "        p+=1\n",
        "    return p/7\n",
        "\n",
        "\n",
        "def calc_likelihood(data, labels, model: XOR_NN):\n",
        "    preds = []\n",
        "    for i in data:\n",
        "        z = model.forward(i)\n",
        "        if z>0.5:\n",
        "            preds.append(1)\n",
        "        else:\n",
        "            preds.append(0)\n",
        "    preds = np.array(preds)-labels\n",
        "    preds = preds.astype(np.float64)\n",
        "    likli = np.count_nonzero(preds==0)/len(preds)\n",
        "    return likli\n",
        "\n",
        "\n",
        "def acceptance(a, b):\n",
        "#     print(b, a)\n",
        "    if b>a:\n",
        "        return True\n",
        "    else:\n",
        "        accept=np.random.uniform(0.25,1)\n",
        "        return (accept < (b-a))\n",
        "\n",
        "\n",
        "def hastings(data, labels, accept, iterations, models: XOR_NN):\n",
        "    #the hastings sampling algorithm\n",
        "    accepted = []\n",
        "    rejected = []   \n",
        "    for i in range(iterations):\n",
        "        x = models.weights\n",
        "        x_new =  gen_temp(x)    \n",
        "        x_lik = calc_likelihood(data, labels, models)\n",
        "        x_new_lik = calc_likelihood(data, labels, x_new) \n",
        "        if i%20 == 0: \n",
        "            print(f'Iteration:{i}: curAcc: {x_lik}, proposedAcc: {x_new_lik}')\n",
        "        if (accept(x_lik*(prior(models)),x_new_lik*(prior(x_new)))):            \n",
        "            models = x_new\n",
        "            accepted.append(x_new)\n",
        "        else:\n",
        "            rejected.append(x_new)            \n",
        "    return np.array(accepted), np.array(rejected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8pLJ-Ew_0xQ"
      },
      "outputs": [],
      "source": [
        "model = XOR_NN(8)\n",
        "\n",
        "accep, rejecc = hastings(data, labels, acceptance, 2000, model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rvtgu2BJRIB4"
      },
      "source": [
        "Getting the best model from all accepted models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJrTFTz1RIB7"
      },
      "outputs": [],
      "source": [
        "x= []\n",
        "for i in accep:\n",
        "    x.append(calc_likelihood(data, labels, i))\n",
        "bestMod= accep[np.argmax(x)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je7GYAN6RIB-"
      },
      "source": [
        "Implementing a random sampler to get baseline acc:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LI2yiRuNRICB"
      },
      "outputs": [],
      "source": [
        "def random_acceptor():\n",
        "    if(np.random.uniform(0,1)>=0.5):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def random_gen_temp(x, random_sig):\n",
        "    templayer1 = np.array(np.random.randn(2,3))*random_sig + x[0]\n",
        "    templayer2 = np.array(np.random.randn(1,3))*random_sig + x[1]\n",
        "    temp = [0, 0]\n",
        "    temp[0] = templayer1\n",
        "    temp[1]= templayer2\n",
        "    temp = np.asarray(temp, dtype = object)\n",
        "    temp_model = XOR_NN()\n",
        "    temp_model.weights = temp\n",
        "    return temp_model\n",
        "\n",
        "def random_sampler(data, labels, iterations, models:XOR_NN):\n",
        "    accepted = []\n",
        "    rejected = []\n",
        "    for i in range(iterations):\n",
        "        x = models.weights\n",
        "        x_new = random_gen_temp(x, abs(np.random.randn()*0.5))\n",
        "        x_lik = calc_likelihood(data, labels, models)\n",
        "        x_new_lik = calc_likelihood(data, labels, x_new)\n",
        "        if i%20 == 0: \n",
        "            print(f'Iteration:{i}: curAcc: {x_lik}, proposedAcc: {x_new_lik}')\n",
        "        if(random_acceptor()):\n",
        "            models = x_new\n",
        "            accepted.append(x_new)\n",
        "        else:\n",
        "            rejected.append(x_new)  \n",
        "    return accepted, rejected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QpM8NndRICE"
      },
      "outputs": [],
      "source": [
        "model = XOR_NN(8)\n",
        "\n",
        "randaccep, randrejecc = random_sampler(data, labels, 1000, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bbr4kWCfRICG"
      },
      "source": [
        "Getting the best model from all accepted models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL54GcFkRICJ"
      },
      "outputs": [],
      "source": [
        "x= []\n",
        "for i in randaccep:\n",
        "    x.append(calc_likelihood(data, labels, i))\n",
        "bestModRandom= randaccep[np.argmax(x)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS39ErmYRICK"
      },
      "source": [
        "<h3> Creating the test set and testsing our model!</h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA3N52odRICL"
      },
      "outputs": [],
      "source": [
        "#so lets create a testset of 1k data points\n",
        "testnum = 1000\n",
        "\n",
        "np.random.seed(0)\n",
        "x1 = np.random.rand(testnum, 1)\n",
        "\n",
        "np.random.seed(1)\n",
        "x2 = np.random.rand(testnum, 1)\n",
        "\n",
        "#creating the dataset\n",
        "testdata = np.hstack((x1, x2))\n",
        "\n",
        "#we will now create the labels using 1:1 corresponding mapping\n",
        "testlabels = np.zeros_like(testdata[:, 0])\n",
        "temp = testdata.copy()\n",
        "temp[temp>=0.5] = 1\n",
        "temp[temp<0.5] = 0\n",
        "temp = temp.astype(np.int32)\n",
        "for i in range(testnum):\n",
        "    testlabels[i] = temp[i][0] ^ temp[i][1] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWp0acmMCDxc"
      },
      "outputs": [],
      "source": [
        "preds = []\n",
        "for i in testdata:\n",
        "    z = bestMod.forward(i)\n",
        "    if z>=0.5:\n",
        "        preds.append(1)\n",
        "    else:\n",
        "        preds.append(0)\n",
        "preds = np.array(preds)-testlabels\n",
        "preds = preds.astype(np.float64)\n",
        "likli = np.count_nonzero(preds==0)/len(preds)\n",
        "print(f'Best Acc:{likli}')\n",
        "\n",
        "for j in testdata:\n",
        "    datapred = []\n",
        "    for i in accep:\n",
        "        z = i.forward(j)\n",
        "        if z>0.5:\n",
        "            datapred.append(1)\n",
        "        else:\n",
        "            datapred.append(0)\n",
        "    z = np.mean(datapred)\n",
        "    if z>=0.5:\n",
        "        predAcc.append(1)\n",
        "    else:\n",
        "        predAcc.append(0)\n",
        "\n",
        "predAcc = np.array(predAcc)-testlabels\n",
        "predAcc = predAcc.astype(np.float64)\n",
        "likli = np.count_nonzero(predAcc==0)/len(predAcc)\n",
        "print(f'Random Ensemble:{likli}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcwSvQZBRICO"
      },
      "outputs": [],
      "source": [
        "# randaccep = accep\n",
        "predsRand = []\n",
        "for i in testdata:\n",
        "    z = bestModRandom.forward(i)\n",
        "    if z>=0.5:\n",
        "        predsRand.append(1)\n",
        "    else:\n",
        "        predsRand.append(0)\n",
        "predsRand = np.array(predsRand)-testlabels\n",
        "predsRand = predsRand.astype(np.float64)\n",
        "likli = np.count_nonzero(predsRand==0)/len(predsRand)\n",
        "print(f'Best Acc:{likli}')\n",
        "\n",
        "predAccRand = []\n",
        "for j in testdata:\n",
        "    datapred = []\n",
        "    for i in randaccep:\n",
        "        z = i.forward(j)\n",
        "        if z>0.5:\n",
        "            datapred.append(1)\n",
        "        else:\n",
        "            datapred.append(0)\n",
        "    z = np.mean(datapred)\n",
        "    if z>=0.5:\n",
        "        predAccRand.append(1)\n",
        "    else:\n",
        "        predAccRand.append(0)\n",
        "\n",
        "predAccRand = np.array(predAccRand)-testlabels\n",
        "predAccRand = predAccRand.astype(np.float64)\n",
        "likli = np.count_nonzero(predAccRand==0)/len(predAccRand)\n",
        "print(f'Random Ensemble:{likli}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1nncjv6RICP"
      },
      "source": [
        "<h3> Save Model!</h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByWQM4D-RICQ"
      },
      "outputs": [],
      "source": [
        "#to save model we just need to save the np array of weights!\n",
        "\n",
        "np.save(\"./bestMod.npy\",bestMod.weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A92emF9oRICS"
      },
      "outputs": [],
      "source": [
        "#to load the model we just need to load the weights!\n",
        "XOR_Model = XOR_NN()\n",
        "XOR_Model.weights = np.load(\"./bestMod.npy\", allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2GqMICeRICT"
      },
      "outputs": [],
      "source": [
        "preds = []\n",
        "for i in testdata:\n",
        "    z = XOR_Model.forward(i)\n",
        "    if z>0.5:\n",
        "        preds.append(1)\n",
        "    else:\n",
        "        preds.append(0)\n",
        "preds = np.array(preds)-testlabels\n",
        "preds = preds.astype(np.float64)\n",
        "likli = np.count_nonzero(preds==0)/len(preds)\n",
        "# likli = ((np.sum(preds*preds))**0.5)/num\n",
        "print(likli)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-e-mlqHRICT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "colab": {
      "collapsed_sections": [],
      "name": "BayesianNN_MCMC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}